{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###predict where the link will be posted given just the title!\n",
    "import pandas as pd\n",
    "from pandas.stats.api import ols\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "train = pd.read_csv('../code/jan_may_2017_links_cross_posting_info.csv')\n",
    "all_pages = list(train.buzz_account_display_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['buzz_external_id', 'buzz_post_parent_external_id',\n",
       "       'buzz_post_created_at', 'buzz_account_display_name',\n",
       "       'buzz_post_type_name', 'buzz_post_buzz_id', 'buzz_campaign_uri',\n",
       "       'buzz_campaign_name', 'ext_table1_stats_date', 'ext_external_id',\n",
       "       ...\n",
       "       'Tasty One-Pot', 'BuzzFeed Sweaty', 'Tasty Junior',\n",
       "       'Oh Great, More Politics', 'Einfach Tasty', 'BuzzFeed Steven L.',\n",
       "       'The Try Guys', 'Ohmygod Yaaa', 'BuzzFeed Chloe', 'Nifty Science'],\n",
       "      dtype='object', length=113)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "starting_features = ['buzz_external_id', 'buzz_account_display_name',\n",
    "       'buzz_post_type_name', 'buzz_post_buzz_id', 'buzz_campaign_uri',\n",
    "       'buzz_campaign_name',]\n",
    "df = train[starting_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###for each buzz_id, get the external ID which was posted FIRST!!!\n",
    "train_grouped = train.groupby(['buzz_post_buzz_id']).agg({'buzz_post_created_at':'min'})\n",
    "\n",
    "train_grouped = train_grouped.reset_index()\n",
    "\n",
    "train_grouped = train_grouped.rename(columns={'buzz_post_created_at':'first_post'})\n",
    "\n",
    "df = pd.merge(train, train_grouped, how='left', on=['buzz_post_buzz_id'])\n",
    "\n",
    "df = df[df['buzz_post_created_at'] == df['first_post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###predict where the link will be posted given just the title!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page:  BuzzFeed Quiz #links:  1316 Accuracy:  0.876523793064 Precision:  0.89950138848 Recall:  0.877731162861 Fscore: 0.874441455809\n",
      "Page:  BuzzFeed Japan #links:  966 Accuracy:  0.778783184659 Precision:  0.868114769689 Recall:  0.791954328994 Fscore: 0.748948276832\n",
      "Page:  BuzzFeed UK #links:  560 Accuracy:  0.705357142857 Precision:  0.781157461487 Recall:  0.708059582881 Fscore: 0.683895185497\n",
      "Page:  BuzzFeed Brasil #links:  1022 Accuracy:  0.954043519847 Precision:  0.956977972847 Recall:  0.955607314823 Fscore: 0.953718606377\n",
      "Page:  BuzzFeed Japan News #links:  616 Accuracy:  0.814221085759 Precision:  0.884922872754 Recall:  0.824908477568 Fscore: 0.790054704583\n",
      "Page:  BuzzFeed Deutschland #links:  581 Accuracy:  0.963881520778 Precision:  0.963885637376 Recall:  0.96701080126 Fscore: 0.963645236684\n",
      "Page:  BuzzFeed News #links:  649 Accuracy:  0.798151460942 Precision:  0.819450358049 Recall:  0.800452731514 Fscore: 0.794210492173\n",
      "Page:  BuzzFeed #links:  978 Accuracy:  0.633417059131 Precision:  0.698704755301 Recall:  0.633948271812 Fscore: 0.600069828277\n",
      "Page:  BuzzFeed Canada #links:  251 Accuracy:  0.706901960784 Precision:  0.765657865738 Recall:  0.706150262781 Fscore: 0.685728994321\n",
      "Page:  BuzzFeed Video #links:  121 Accuracy:  0.6315 Precision:  0.742401683023 Recall:  0.63618006993 Fscore: 0.577839243216\n",
      "Page:  Cocoa Butter #links:  177 Accuracy:  0.675476190476 Precision:  0.735914487811 Recall:  0.685563284325 Fscore: 0.654046905393\n",
      "Page:  BuzzFeed Oz Politics #links:  212 Accuracy:  0.834440753045 Precision:  0.869409480638 Recall:  0.841575831629 Fscore: 0.830276103453\n",
      "Page:  Quizzes En Español #links:  195 Accuracy:  0.907692307692 Precision:  0.918740730284 Recall:  0.912691752692 Fscore: 0.905513988573\n",
      "Page:  Obsessed by BuzzFeed #links:  292 Accuracy:  0.724605493863 Precision:  0.782228497127 Recall:  0.726041660834 Fscore: 0.708143720893\n",
      "Page:  BuzzFeed News BR #links:  278 Accuracy:  0.940584415584 Precision:  0.94630624913 Recall:  0.94201695681 Fscore: 0.939637432848\n",
      "Page:  Buy Me That #links:  362 Accuracy:  0.82595129376 Precision:  0.864178006216 Recall:  0.827446642079 Fscore: 0.820698758682\n",
      "Page:  BuzzFeed UK Politics #links:  256 Accuracy:  0.841704374057 Precision:  0.871508122188 Recall:  0.843456635957 Fscore: 0.837906976329\n",
      "Page:  BuzzFeed Australia #links:  718 Accuracy:  0.688723776224 Precision:  0.763521893883 Recall:  0.690296538653 Fscore: 0.66434792934\n",
      "Page:  BuzzFeed Rewind #links:  220 Accuracy:  0.718181818182 Precision:  0.805826346304 Recall:  0.720803218521 Fscore: 0.694392133716\n",
      "Page:  BuzzFeed Books #links:  210 Accuracy:  0.690476190476 Precision:  0.762477870863 Recall:  0.689182777981 Fscore: 0.657329380717\n",
      "Page:  BuzzFeed DIY #links:  260 Accuracy:  0.742307692308 Precision:  0.772348607101 Recall:  0.743022018128 Fscore: 0.733744215877\n",
      "Page:  BuzzFeed México #links:  665 Accuracy:  0.93007518797 Precision:  0.940123012952 Recall:  0.932060980306 Fscore: 0.929640802357\n",
      "Page:  BuzzFeed Food #links:  545 Accuracy:  0.752293577982 Precision:  0.817081465185 Recall:  0.754040611499 Fscore: 0.737761044305\n",
      "Page:  BuzzFeed Celeb #links:  480 Accuracy:  0.744791666667 Precision:  0.791546333208 Recall:  0.748869263913 Fscore: 0.733878019398\n",
      "Page:  BuzzFeed Animals #links:  268 Accuracy:  0.759014675052 Precision:  0.832304066085 Recall:  0.761783104975 Fscore: 0.742791279261\n",
      "Page:  BuzzFeed France #links:  546 Accuracy:  0.957889908257 Precision:  0.960471837161 Recall:  0.959344111349 Fscore: 0.957642643535\n",
      "Page:  BuzzFeed Español #links:  386 Accuracy:  0.907858807859 Precision:  0.920773904484 Recall:  0.912191395612 Fscore: 0.906614057661\n",
      "Page:  BuzzFeed Style #links:  409 Accuracy:  0.715055706113 Precision:  0.80235939997 Recall:  0.716479688478 Fscore: 0.6921827402\n",
      "Page:  Cheeky #links:  364 Accuracy:  0.776084474886 Precision:  0.815162427171 Recall:  0.781524651495 Fscore: 0.769330642693\n",
      "Page:  BuzzFeed Community #links:  348 Accuracy:  0.722567287785 Precision:  0.797747527756 Recall:  0.727159031886 Fscore: 0.704696764767\n",
      "Page:  BuzzFeed Weddings #links:  112 Accuracy:  0.643675889328 Precision:  0.735710270552 Recall:  0.660914502165 Fscore: 0.611167273595\n",
      "Page:  BuzzFeed World #links:  243 Accuracy:  0.802465986395 Precision:  0.834564169754 Recall:  0.800718597663 Fscore: 0.790792019177\n",
      "Page:  BuzzFeed Entertainment #links:  344 Accuracy:  0.739791133845 Precision:  0.784541046966 Recall:  0.743480894515 Fscore: 0.7276637488\n",
      "Page:  BuzzFeed Geeky #links:  142 Accuracy:  0.641009852217 Precision:  0.691247930813 Recall:  0.645856614146 Fscore: 0.603491857667\n",
      "Page:  BuzzFeed Parents #links:  189 Accuracy:  0.708748221906 Precision:  0.786367181669 Recall:  0.709882095356 Fscore: 0.685062564783\n",
      "Page:  BuzzFeed Health #links:  298 Accuracy:  0.680988700565 Precision:  0.743103890565 Recall:  0.686961479741 Fscore: 0.659024836347\n",
      "Page:  BuzzFeed España #links:  357 Accuracy:  0.920148669797 Precision:  0.930945360945 Recall:  0.921525895112 Fscore: 0.919332493457\n",
      "Page:  BuzzFeed Politics #links:  378 Accuracy:  0.866350877193 Precision:  0.889022307724 Recall:  0.870604067 Fscore: 0.864392522602\n",
      "Page:  Pero Like #links:  45 Accuracy:  0.555555555556 Precision:  0.607738095238 Recall:  0.561428571429 Fscore: 0.510994005994\n",
      "Page:  BuzzFeed UK News #links:  366 Accuracy:  0.779914846353 Precision:  0.812658739625 Recall:  0.781882126337 Fscore: 0.772360582267\n",
      "Page:  BuzzFeed India #links:  620 Accuracy:  0.729838709677 Precision:  0.795698466974 Recall:  0.7330655776 Fscore: 0.713846779956\n",
      "Page:  BuzzFeed France News #links:  217 Accuracy:  0.924048625793 Precision:  0.931044004198 Recall:  0.926811134115 Fscore: 0.922035401097\n",
      "Page:  BuzzFeed Scotland #links:  96 Accuracy:  0.676842105263 Precision:  0.797633053221 Recall:  0.70974969475 Fscore: 0.646460854766\n",
      "Page:  LOLA #links:  37 Accuracy:  0.916071428571 Precision:  0.920833333333 Recall:  0.919166666667 Fscore: 0.899401154401\n",
      "Page:  BuzzFeed Philippines #links:  161 Accuracy:  0.727083333333 Precision:  0.785217696152 Recall:  0.729435405066 Fscore: 0.710421330505\n",
      "Page:  BuzzFeed Oz News #links:  179 Accuracy:  0.779365079365 Precision:  0.80234313984 Recall:  0.780404657477 Fscore: 0.773560310479\n",
      "Page:  BuzzFeed Reader #links:  46 Accuracy:  0.757777777778 Precision:  0.806071428571 Recall:  0.784285714286 Fscore: 0.750396270396\n",
      "Page:  BuzzFeed Pink #links:  25 Accuracy:  0.84 Precision:  0.879166666667 Recall:  0.875 Fscore: 0.83119047619\n",
      "Page:  BuzzFeed LGBT #links:  114 Accuracy:  0.702371541502 Precision:  0.769074793885 Recall:  0.702880730381 Fscore: 0.675183108127\n",
      "Page:  BuzzFeed Partner #links:  89 Accuracy:  0.690522875817 Precision:  0.763363858364 Recall:  0.687968420468 Fscore: 0.650663801653\n",
      "Page:  BuzzFeed Tech #links:  211 Accuracy:  0.817497231451 Precision:  0.83689231388 Recall:  0.821526959695 Fscore: 0.812269173773\n",
      "Page:  BuzzFeed Science #links:  73 Accuracy:  0.733333333333 Precision:  0.793019480519 Recall:  0.740943362193 Fscore: 0.716880397724\n"
     ]
    }
   ],
   "source": [
    "###predict where the link will be posted given just the title!\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "pages = []\n",
    "num_links = []\n",
    "average_acc = []\n",
    "average_pre = []\n",
    "average_rec = []\n",
    "average_f1 = []\n",
    "cv_folds = 10\n",
    "results = pd.DataFrame()\n",
    "page_clf = []\n",
    "\n",
    "for test_page in all_pages:\n",
    "#     test_page = \"BuzzFeed\"\n",
    "    X_1 = df[df.buzz_account_display_name == test_page]\n",
    "    X_0 = df[~(df.buzz_account_display_name == test_page)].sample(n=len(X_1))\n",
    "    if len(X_1) < 2.5*cv_folds:\n",
    "        continue\n",
    "    X_1 = X_1[['buzz_campaign_name', 'buzz_account_display_name']]\n",
    "    X_0 = X_0[['buzz_campaign_name', 'buzz_account_display_name']]\n",
    "\n",
    "    X_all = pd.concat([X_1, X_0])\n",
    "\n",
    "    def get_class(X, page):\n",
    "        if X == page:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    X_all['class'] = X_all['buzz_account_display_name'].apply(get_class, page = test_page)\n",
    "\n",
    "    X_all = X_all.dropna()\n",
    "\n",
    "    text_clf = Pipeline([\n",
    "                         ('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "#                          ('featselect', SelectKBest(k = 100)),\n",
    "                         ('clf', MultinomialNB()),\n",
    "#                          ('clf', LinearSVC()),\n",
    "#                          ('clf', RandomForestClassifier()),\n",
    "#                          ('clf', LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "    fold = 0\n",
    "    kf = KFold(n_splits = cv_folds, shuffle = True)\n",
    "\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "\n",
    "    X = X_all['buzz_campaign_name']\n",
    "    y = X_all['class']\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "#         print(\"Fold = \", fold)\n",
    "        fold+= 1\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        text_clf.fit(X_train, y_train)\n",
    "        y_pred = text_clf.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec, rec, fs, sup = precision_recall_fscore_support(y_test, y_pred)\n",
    "        accuracy.append(acc)\n",
    "        precision.append(prec)\n",
    "        recall.append(rec)\n",
    "        fscore.append(fs)\n",
    "    print(\"Page: \", test_page, \"#links: \", len(X_1), \"Accuracy: \", np.mean(accuracy), \"Precision: \", np.mean(precision), \"Recall: \", np.mean(recall), \"Fscore:\", np.mean(fscore))\n",
    "    num_links.append(len(X_1))\n",
    "    average_acc.append(np.mean(accuracy))\n",
    "    average_pre.append(np.mean(precision))\n",
    "    average_rec.append(np.mean(recall))\n",
    "    average_f1.append(np.mean(fscore))\n",
    "    pages.append(test_page)\n",
    "    page_clf.append(text_clf)\n",
    "results['page'] = pages\n",
    "results['num_links'] = num_links\n",
    "results['accuracy'] = average_acc\n",
    "results['precision'] = average_pre\n",
    "results['recall'] = average_rec\n",
    "results['fscore'] = average_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>num_links</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BuzzFeed Quiz</td>\n",
       "      <td>1316</td>\n",
       "      <td>0.876524</td>\n",
       "      <td>0.899501</td>\n",
       "      <td>0.877731</td>\n",
       "      <td>0.874441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BuzzFeed Japan</td>\n",
       "      <td>966</td>\n",
       "      <td>0.778783</td>\n",
       "      <td>0.868115</td>\n",
       "      <td>0.791954</td>\n",
       "      <td>0.748948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BuzzFeed UK</td>\n",
       "      <td>560</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.781157</td>\n",
       "      <td>0.708060</td>\n",
       "      <td>0.683895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BuzzFeed Brasil</td>\n",
       "      <td>1022</td>\n",
       "      <td>0.954044</td>\n",
       "      <td>0.956978</td>\n",
       "      <td>0.955607</td>\n",
       "      <td>0.953719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BuzzFeed Japan News</td>\n",
       "      <td>616</td>\n",
       "      <td>0.814221</td>\n",
       "      <td>0.884923</td>\n",
       "      <td>0.824908</td>\n",
       "      <td>0.790055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BuzzFeed Deutschland</td>\n",
       "      <td>581</td>\n",
       "      <td>0.963882</td>\n",
       "      <td>0.963886</td>\n",
       "      <td>0.967011</td>\n",
       "      <td>0.963645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>649</td>\n",
       "      <td>0.798151</td>\n",
       "      <td>0.819450</td>\n",
       "      <td>0.800453</td>\n",
       "      <td>0.794210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>978</td>\n",
       "      <td>0.633417</td>\n",
       "      <td>0.698705</td>\n",
       "      <td>0.633948</td>\n",
       "      <td>0.600070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BuzzFeed Canada</td>\n",
       "      <td>251</td>\n",
       "      <td>0.706902</td>\n",
       "      <td>0.765658</td>\n",
       "      <td>0.706150</td>\n",
       "      <td>0.685729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BuzzFeed Video</td>\n",
       "      <td>121</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.742402</td>\n",
       "      <td>0.636180</td>\n",
       "      <td>0.577839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cocoa Butter</td>\n",
       "      <td>177</td>\n",
       "      <td>0.675476</td>\n",
       "      <td>0.735914</td>\n",
       "      <td>0.685563</td>\n",
       "      <td>0.654047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BuzzFeed Oz Politics</td>\n",
       "      <td>212</td>\n",
       "      <td>0.834441</td>\n",
       "      <td>0.869409</td>\n",
       "      <td>0.841576</td>\n",
       "      <td>0.830276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Quizzes En Español</td>\n",
       "      <td>195</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.918741</td>\n",
       "      <td>0.912692</td>\n",
       "      <td>0.905514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Obsessed by BuzzFeed</td>\n",
       "      <td>292</td>\n",
       "      <td>0.724605</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>0.726042</td>\n",
       "      <td>0.708144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BuzzFeed News BR</td>\n",
       "      <td>278</td>\n",
       "      <td>0.940584</td>\n",
       "      <td>0.946306</td>\n",
       "      <td>0.942017</td>\n",
       "      <td>0.939637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Buy Me That</td>\n",
       "      <td>362</td>\n",
       "      <td>0.825951</td>\n",
       "      <td>0.864178</td>\n",
       "      <td>0.827447</td>\n",
       "      <td>0.820699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BuzzFeed UK Politics</td>\n",
       "      <td>256</td>\n",
       "      <td>0.841704</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>0.843457</td>\n",
       "      <td>0.837907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BuzzFeed Australia</td>\n",
       "      <td>718</td>\n",
       "      <td>0.688724</td>\n",
       "      <td>0.763522</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>0.664348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BuzzFeed Rewind</td>\n",
       "      <td>220</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.805826</td>\n",
       "      <td>0.720803</td>\n",
       "      <td>0.694392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BuzzFeed Books</td>\n",
       "      <td>210</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.762478</td>\n",
       "      <td>0.689183</td>\n",
       "      <td>0.657329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BuzzFeed DIY</td>\n",
       "      <td>260</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.772349</td>\n",
       "      <td>0.743022</td>\n",
       "      <td>0.733744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BuzzFeed México</td>\n",
       "      <td>665</td>\n",
       "      <td>0.930075</td>\n",
       "      <td>0.940123</td>\n",
       "      <td>0.932061</td>\n",
       "      <td>0.929641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BuzzFeed Food</td>\n",
       "      <td>545</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.817081</td>\n",
       "      <td>0.754041</td>\n",
       "      <td>0.737761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BuzzFeed Celeb</td>\n",
       "      <td>480</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.791546</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.733878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BuzzFeed Animals</td>\n",
       "      <td>268</td>\n",
       "      <td>0.759015</td>\n",
       "      <td>0.832304</td>\n",
       "      <td>0.761783</td>\n",
       "      <td>0.742791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BuzzFeed France</td>\n",
       "      <td>546</td>\n",
       "      <td>0.957890</td>\n",
       "      <td>0.960472</td>\n",
       "      <td>0.959344</td>\n",
       "      <td>0.957643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BuzzFeed Español</td>\n",
       "      <td>386</td>\n",
       "      <td>0.907859</td>\n",
       "      <td>0.920774</td>\n",
       "      <td>0.912191</td>\n",
       "      <td>0.906614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BuzzFeed Style</td>\n",
       "      <td>409</td>\n",
       "      <td>0.715056</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>0.716480</td>\n",
       "      <td>0.692183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cheeky</td>\n",
       "      <td>364</td>\n",
       "      <td>0.776084</td>\n",
       "      <td>0.815162</td>\n",
       "      <td>0.781525</td>\n",
       "      <td>0.769331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BuzzFeed Community</td>\n",
       "      <td>348</td>\n",
       "      <td>0.722567</td>\n",
       "      <td>0.797748</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>0.704697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BuzzFeed Weddings</td>\n",
       "      <td>112</td>\n",
       "      <td>0.643676</td>\n",
       "      <td>0.735710</td>\n",
       "      <td>0.660915</td>\n",
       "      <td>0.611167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BuzzFeed World</td>\n",
       "      <td>243</td>\n",
       "      <td>0.802466</td>\n",
       "      <td>0.834564</td>\n",
       "      <td>0.800719</td>\n",
       "      <td>0.790792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BuzzFeed Entertainment</td>\n",
       "      <td>344</td>\n",
       "      <td>0.739791</td>\n",
       "      <td>0.784541</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>0.727664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BuzzFeed Geeky</td>\n",
       "      <td>142</td>\n",
       "      <td>0.641010</td>\n",
       "      <td>0.691248</td>\n",
       "      <td>0.645857</td>\n",
       "      <td>0.603492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BuzzFeed Parents</td>\n",
       "      <td>189</td>\n",
       "      <td>0.708748</td>\n",
       "      <td>0.786367</td>\n",
       "      <td>0.709882</td>\n",
       "      <td>0.685063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BuzzFeed Health</td>\n",
       "      <td>298</td>\n",
       "      <td>0.680989</td>\n",
       "      <td>0.743104</td>\n",
       "      <td>0.686961</td>\n",
       "      <td>0.659025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BuzzFeed España</td>\n",
       "      <td>357</td>\n",
       "      <td>0.920149</td>\n",
       "      <td>0.930945</td>\n",
       "      <td>0.921526</td>\n",
       "      <td>0.919332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BuzzFeed Politics</td>\n",
       "      <td>378</td>\n",
       "      <td>0.866351</td>\n",
       "      <td>0.889022</td>\n",
       "      <td>0.870604</td>\n",
       "      <td>0.864393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pero Like</td>\n",
       "      <td>45</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.607738</td>\n",
       "      <td>0.561429</td>\n",
       "      <td>0.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BuzzFeed UK News</td>\n",
       "      <td>366</td>\n",
       "      <td>0.779915</td>\n",
       "      <td>0.812659</td>\n",
       "      <td>0.781882</td>\n",
       "      <td>0.772361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>BuzzFeed India</td>\n",
       "      <td>620</td>\n",
       "      <td>0.729839</td>\n",
       "      <td>0.795698</td>\n",
       "      <td>0.733066</td>\n",
       "      <td>0.713847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>BuzzFeed France News</td>\n",
       "      <td>217</td>\n",
       "      <td>0.924049</td>\n",
       "      <td>0.931044</td>\n",
       "      <td>0.926811</td>\n",
       "      <td>0.922035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BuzzFeed Scotland</td>\n",
       "      <td>96</td>\n",
       "      <td>0.676842</td>\n",
       "      <td>0.797633</td>\n",
       "      <td>0.709750</td>\n",
       "      <td>0.646461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LOLA</td>\n",
       "      <td>37</td>\n",
       "      <td>0.916071</td>\n",
       "      <td>0.920833</td>\n",
       "      <td>0.919167</td>\n",
       "      <td>0.899401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BuzzFeed Philippines</td>\n",
       "      <td>161</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.785218</td>\n",
       "      <td>0.729435</td>\n",
       "      <td>0.710421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BuzzFeed Oz News</td>\n",
       "      <td>179</td>\n",
       "      <td>0.779365</td>\n",
       "      <td>0.802343</td>\n",
       "      <td>0.780405</td>\n",
       "      <td>0.773560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BuzzFeed Reader</td>\n",
       "      <td>46</td>\n",
       "      <td>0.757778</td>\n",
       "      <td>0.806071</td>\n",
       "      <td>0.784286</td>\n",
       "      <td>0.750396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BuzzFeed Pink</td>\n",
       "      <td>25</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.831190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BuzzFeed LGBT</td>\n",
       "      <td>114</td>\n",
       "      <td>0.702372</td>\n",
       "      <td>0.769075</td>\n",
       "      <td>0.702881</td>\n",
       "      <td>0.675183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>BuzzFeed Partner</td>\n",
       "      <td>89</td>\n",
       "      <td>0.690523</td>\n",
       "      <td>0.763364</td>\n",
       "      <td>0.687968</td>\n",
       "      <td>0.650664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BuzzFeed Tech</td>\n",
       "      <td>211</td>\n",
       "      <td>0.817497</td>\n",
       "      <td>0.836892</td>\n",
       "      <td>0.821527</td>\n",
       "      <td>0.812269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>73</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.793019</td>\n",
       "      <td>0.740943</td>\n",
       "      <td>0.716880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      page  num_links  accuracy  precision    recall    fscore\n",
       "0            BuzzFeed Quiz       1316  0.876524   0.899501  0.877731  0.874441\n",
       "1           BuzzFeed Japan        966  0.778783   0.868115  0.791954  0.748948\n",
       "2              BuzzFeed UK        560  0.705357   0.781157  0.708060  0.683895\n",
       "3          BuzzFeed Brasil       1022  0.954044   0.956978  0.955607  0.953719\n",
       "4      BuzzFeed Japan News        616  0.814221   0.884923  0.824908  0.790055\n",
       "5     BuzzFeed Deutschland        581  0.963882   0.963886  0.967011  0.963645\n",
       "6            BuzzFeed News        649  0.798151   0.819450  0.800453  0.794210\n",
       "7                 BuzzFeed        978  0.633417   0.698705  0.633948  0.600070\n",
       "8          BuzzFeed Canada        251  0.706902   0.765658  0.706150  0.685729\n",
       "9           BuzzFeed Video        121  0.631500   0.742402  0.636180  0.577839\n",
       "10            Cocoa Butter        177  0.675476   0.735914  0.685563  0.654047\n",
       "11    BuzzFeed Oz Politics        212  0.834441   0.869409  0.841576  0.830276\n",
       "12      Quizzes En Español        195  0.907692   0.918741  0.912692  0.905514\n",
       "13    Obsessed by BuzzFeed        292  0.724605   0.782228  0.726042  0.708144\n",
       "14        BuzzFeed News BR        278  0.940584   0.946306  0.942017  0.939637\n",
       "15             Buy Me That        362  0.825951   0.864178  0.827447  0.820699\n",
       "16    BuzzFeed UK Politics        256  0.841704   0.871508  0.843457  0.837907\n",
       "17      BuzzFeed Australia        718  0.688724   0.763522  0.690297  0.664348\n",
       "18         BuzzFeed Rewind        220  0.718182   0.805826  0.720803  0.694392\n",
       "19          BuzzFeed Books        210  0.690476   0.762478  0.689183  0.657329\n",
       "20            BuzzFeed DIY        260  0.742308   0.772349  0.743022  0.733744\n",
       "21         BuzzFeed México        665  0.930075   0.940123  0.932061  0.929641\n",
       "22           BuzzFeed Food        545  0.752294   0.817081  0.754041  0.737761\n",
       "23          BuzzFeed Celeb        480  0.744792   0.791546  0.748869  0.733878\n",
       "24        BuzzFeed Animals        268  0.759015   0.832304  0.761783  0.742791\n",
       "25         BuzzFeed France        546  0.957890   0.960472  0.959344  0.957643\n",
       "26        BuzzFeed Español        386  0.907859   0.920774  0.912191  0.906614\n",
       "27          BuzzFeed Style        409  0.715056   0.802359  0.716480  0.692183\n",
       "28                  Cheeky        364  0.776084   0.815162  0.781525  0.769331\n",
       "29      BuzzFeed Community        348  0.722567   0.797748  0.727159  0.704697\n",
       "30       BuzzFeed Weddings        112  0.643676   0.735710  0.660915  0.611167\n",
       "31          BuzzFeed World        243  0.802466   0.834564  0.800719  0.790792\n",
       "32  BuzzFeed Entertainment        344  0.739791   0.784541  0.743481  0.727664\n",
       "33          BuzzFeed Geeky        142  0.641010   0.691248  0.645857  0.603492\n",
       "34        BuzzFeed Parents        189  0.708748   0.786367  0.709882  0.685063\n",
       "35         BuzzFeed Health        298  0.680989   0.743104  0.686961  0.659025\n",
       "36         BuzzFeed España        357  0.920149   0.930945  0.921526  0.919332\n",
       "37       BuzzFeed Politics        378  0.866351   0.889022  0.870604  0.864393\n",
       "38               Pero Like         45  0.555556   0.607738  0.561429  0.510994\n",
       "39        BuzzFeed UK News        366  0.779915   0.812659  0.781882  0.772361\n",
       "40          BuzzFeed India        620  0.729839   0.795698  0.733066  0.713847\n",
       "41    BuzzFeed France News        217  0.924049   0.931044  0.926811  0.922035\n",
       "42       BuzzFeed Scotland         96  0.676842   0.797633  0.709750  0.646461\n",
       "43                    LOLA         37  0.916071   0.920833  0.919167  0.899401\n",
       "44    BuzzFeed Philippines        161  0.727083   0.785218  0.729435  0.710421\n",
       "45        BuzzFeed Oz News        179  0.779365   0.802343  0.780405  0.773560\n",
       "46         BuzzFeed Reader         46  0.757778   0.806071  0.784286  0.750396\n",
       "47           BuzzFeed Pink         25  0.840000   0.879167  0.875000  0.831190\n",
       "48           BuzzFeed LGBT        114  0.702372   0.769075  0.702881  0.675183\n",
       "49        BuzzFeed Partner         89  0.690523   0.763364  0.687968  0.650664\n",
       "50           BuzzFeed Tech        211  0.817497   0.836892  0.821527  0.812269\n",
       "51        BuzzFeed Science         73  0.733333   0.793019  0.740943  0.716880"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_links    357.557692\n",
       "accuracy       0.775999\n",
       "precision      0.823982\n",
       "recall         0.781001\n",
       "fscore         0.760379\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BuzzFeed Quiz 0.872023265736\n",
      "BuzzFeed Japan 0.0232061402676\n",
      "BuzzFeed UK 0.639373371345\n",
      "BuzzFeed Brasil 0.0159616094542\n",
      "BuzzFeed Japan News 0.0546786379889\n",
      "BuzzFeed Deutschland 0.0392927380669\n",
      "BuzzFeed News 0.344790621089\n",
      "BuzzFeed 0.720540555956\n",
      "BuzzFeed Canada 0.688683690492\n",
      "BuzzFeed Video 0.441653668603\n",
      "Cocoa Butter 0.559871552776\n",
      "BuzzFeed Oz Politics 0.29647916799\n",
      "Quizzes En Español 0.165538767967\n",
      "Obsessed by BuzzFeed 0.512451840258\n",
      "BuzzFeed News BR 0.077149748131\n",
      "Buy Me That 0.458684628105\n",
      "BuzzFeed UK Politics 0.418383819611\n",
      "BuzzFeed Australia 0.666488964193\n",
      "BuzzFeed Rewind 0.5358195718\n",
      "Woops, the model for page  BuzzFeed Ladylike  is still in the works!\n",
      "BuzzFeed Books 0.658604598769\n",
      "BuzzFeed DIY 0.557135392623\n",
      "BuzzFeed México 0.0642621895175\n",
      "BuzzFeed Food 0.609404586826\n",
      "BuzzFeed Celeb 0.648610538258\n",
      "BuzzFeed Animals 0.805783224629\n",
      "BuzzFeed France 0.0500671445182\n",
      "BuzzFeed Español 0.0780864748339\n",
      "BuzzFeed Style 0.495625910281\n",
      "Woops, the model for page  Tasty  is still in the works!\n",
      "Cheeky 0.46184884669\n",
      "BuzzFeed Community 0.576448550984\n",
      "BuzzFeed Weddings 0.427224976448\n",
      "Woops, the model for page  Tasty Demais  is still in the works!\n",
      "BuzzFeed World 0.483761855881\n",
      "Woops, the model for page  SOML  is still in the works!\n",
      "BuzzFeed Entertainment 0.665409927008\n",
      "BuzzFeed Geeky 0.648596680081\n",
      "BuzzFeed Parents 0.630845112315\n",
      "BuzzFeed Health 0.794480471073\n",
      "BuzzFeed España 0.104480685725\n",
      "BuzzFeed Politics 0.260182647936\n",
      "Pero Like 0.43694553317\n",
      "BuzzFeed UK News 0.42448456961\n",
      "BuzzFeed India 0.45262247854\n",
      "BuzzFeed France News 0.114407844775\n",
      "BuzzFeed Scotland 0.601641166947\n",
      "LOLA 0.263476086847\n",
      "BuzzFeed Philippines 0.549281886935\n",
      "BuzzFeed Oz News 0.536948653168\n",
      "Woops, the model for page  BuzzFeed Unsolved  is still in the works!\n",
      "Woops, the model for page  BuzzFeed IRL  is still in the works!\n",
      "Woops, the model for page  Bien Tasty  is still in the works!\n",
      "BuzzFeed Reader 0.469079058941\n",
      "BuzzFeed Pink 0.316053931952\n",
      "BuzzFeed LGBT 0.653804392704\n",
      "BuzzFeed Partner 0.815711794116\n",
      "Woops, the model for page  So Relatable  is still in the works!\n",
      "Woops, the model for page  BuzzFeed Open Lab  is still in the works!\n",
      "BuzzFeed Tech 0.535939064542\n",
      "BuzzFeed Science 0.561377155304\n",
      "Woops, the model for page  Reasons to Smile  is still in the works!\n",
      "Woops, the model for page  Tasty Miam  is still in the works!\n",
      "Woops, the model for page  Proper Tasty  is still in the works!\n",
      "Woops, the model for page  BuzzFeed San Francisco  is still in the works!\n",
      "Woops, the model for page  BuzzFeed Shane  is still in the works!\n",
      "Woops, the model for page  BuzzFeed Ryan  is still in the works!\n",
      "Woops, the model for page  Nifty  is still in the works!\n",
      "Woops, the model for page  See Something Say Something  is still in the works!\n",
      "Woops, the model for page  Tasty Japan  is still in the works!\n",
      "Woops, the model for page  BuzzFeed Zack  is still in the works!\n",
      "Woops, the model for page  Kristin Chirico  is still in the works!\n",
      "Woops, the model for page  BuzzFeed Austin  is still in the works!\n",
      "Woops, the model for page  Adam Ellis  is still in the works!\n",
      "Woops, the model for page  Another Round  is still in the works!\n",
      "Woops, the model for page  Top Knot  is still in the works!\n",
      "Woops, the model for page  Buzzed Feed  is still in the works!\n",
      "Woops, the model for page  BuzzFeed BFF  is still in the works!\n",
      "Woops, the model for page  Tasty One-Pot  is still in the works!\n",
      "Woops, the model for page  BuzzFeed Sweaty  is still in the works!\n",
      "Woops, the model for page  Tasty Junior  is still in the works!\n",
      "Woops, the model for page  Oh Great, More Politics  is still in the works!\n",
      "Woops, the model for page  Einfach Tasty  is still in the works!\n",
      "Woops, the model for page  BuzzFeed Steven L.  is still in the works!\n",
      "Woops, the model for page  The Try Guys  is still in the works!\n",
      "Woops, the model for page  Ohmygod Yaaa  is still in the works!\n",
      "Woops, the model for page  BuzzFeed Chloe  is still in the works!\n",
      "Woops, the model for page  Nifty Science  is still in the works!\n",
      "Best fit for this link would be:  BuzzFeed Quiz\n"
     ]
    }
   ],
   "source": [
    "#####Query by page and title of link - Should a link with this title be posted on this BF page?\n",
    "# q_page = \"LOLA\"\n",
    "q_page = \"BuzzFeed Quiz\"\n",
    "# q_page = \"BuzzFeed Japan\"\n",
    "q_test = [\"Find Out What your spirit animal is?\"]  ###list of titles you wanna query\n",
    "\n",
    "max_prob = 0\n",
    "max_page = \"\"\n",
    "\n",
    "for pg in all_pages:\n",
    "    try:\n",
    "        clf = page_clf[pages.index(pg)]\n",
    "    except:\n",
    "        print(\"Woops, the model for page \", pg, \" is still in the works!\")\n",
    "        continue\n",
    "        \n",
    "    prob = clf.predict_proba(q_test)[0][1]\n",
    "    print(pg, prob)\n",
    "    if prob > max_prob:\n",
    "        max_prob = prob\n",
    "        max_page = pg\n",
    "    \n",
    "print(\"Best fit for this link would be: \", max_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BuzzFeed Quiz', 0.87202326573578171)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_page, max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buzz_campaign_name</th>\n",
       "      <th>buzz_account_display_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>Caltech Professor Who Harassed Women Was Also ...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>The CEO Of A Huge Chicken Company Denied That ...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>A NASA Spacecraft Has Found Northern Lights An...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>Scientists Tell Navajo Farmers Their Water Is ...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>Why Americans Are So Damn Unhealthy, In 4 Shoc...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606</th>\n",
       "      <td>This Is Why You Should Always Shower Before Sw...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>A Photographer Captured A Jaw-Dropping Weather...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>A Shocking 51-49 Senate Vote Just Kept Obama's...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>A Scientist Is Leaving Google For A Mental Hea...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8190</th>\n",
       "      <td>Obama Warns Inequality Could Derail Climate Ch...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>There's A Storm On Saturn And People Think It ...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10508</th>\n",
       "      <td>This Study Adds Even More Weight To Scientists...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10613</th>\n",
       "      <td>This Is Why Everyone Got Confused About The &amp;q...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11477</th>\n",
       "      <td>Despite Donald Trump, Medical Science Just Got...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12057</th>\n",
       "      <td>Just A Bunch Of Truly Awesome Signs From The P...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13357</th>\n",
       "      <td>Don’t Believe The Big Story About Humans Roami...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13671</th>\n",
       "      <td>This Guy Gorged On Fish For A Year To See If O...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>Trump Is Ordering A Review Of All National Mon...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13875</th>\n",
       "      <td>The Science March Was Political. Its Organizer...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14549</th>\n",
       "      <td>These Native American Scholars Marched For Ind...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14628</th>\n",
       "      <td>15 Climate Change Facts That You'll Know Are T...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14674</th>\n",
       "      <td>These March For Science Signs Are So Wonderful...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15077</th>\n",
       "      <td>This Is What The World Looks Like Without Water</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15654</th>\n",
       "      <td>The Opioid Epidemic Is Actually Two Epidemics</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15883</th>\n",
       "      <td>This Planet Around A Small, Cool Star May Be O...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15946</th>\n",
       "      <td>26 Science Tweets That Will Leave You Shook</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17920</th>\n",
       "      <td>These Takeout Robots Won't Wipe Out Delivery J...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18024</th>\n",
       "      <td>California Shows The Rest Of The Country How T...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>This Sky Pool Lets You Swim Suspended 500 Feet...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20881</th>\n",
       "      <td>17 Cheat Sheets That Will Actually Help You Sl...</td>\n",
       "      <td>BuzzFeed Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10528</th>\n",
       "      <td>Le résumé pas chiant du débat Macron-Le Pen</td>\n",
       "      <td>BuzzFeed France News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28562</th>\n",
       "      <td>12 situações em que as pessoas dramáticas semp...</td>\n",
       "      <td>BuzzFeed Brasil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29330</th>\n",
       "      <td>27 Things We Learned On Set With Dua Lipa</td>\n",
       "      <td>BuzzFeed Celeb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25063</th>\n",
       "      <td>18 blagues que tous les fans d'Harry Potter ap...</td>\n",
       "      <td>BuzzFeed France</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32851</th>\n",
       "      <td>9 Interesting Theories About Who The \"Riverdal...</td>\n",
       "      <td>BuzzFeed Australia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27804</th>\n",
       "      <td>Les différences entre les universités français...</td>\n",
       "      <td>BuzzFeed France</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17655</th>\n",
       "      <td>The Ultimate &amp;quot;RuPaul's Drag Race&amp;quot; Se...</td>\n",
       "      <td>BuzzFeed LGBT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32112</th>\n",
       "      <td>Here's Why The World's Biggest Brands Are Blac...</td>\n",
       "      <td>BuzzFeed Politics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26576</th>\n",
       "      <td>21 Secretos que los blogueros de comida nunca ...</td>\n",
       "      <td>BuzzFeed Español</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27641</th>\n",
       "      <td>We Know The Exact Date You'll Be Abducted By A...</td>\n",
       "      <td>BuzzFeed Quiz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19539</th>\n",
       "      <td>Este quiz de comida te dirá si te sobra o te f...</td>\n",
       "      <td>Quizzes En Español</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27902</th>\n",
       "      <td>Here Is The Winner Of The \"One Book, One New Y...</td>\n",
       "      <td>BuzzFeed Reader</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31617</th>\n",
       "      <td>Theresa May Has Asked MPs To Help End Violence...</td>\n",
       "      <td>BuzzFeed UK Politics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15893</th>\n",
       "      <td>Leave It To Tyler, The Creator And Bill Nye To...</td>\n",
       "      <td>Obsessed by BuzzFeed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20548</th>\n",
       "      <td>11 Struggles That Kinda Suck When Trying To Ge...</td>\n",
       "      <td>BuzzFeed Australia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28526</th>\n",
       "      <td>Si vous ne portez que des vêtements noirs, vou...</td>\n",
       "      <td>BuzzFeed France</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30676</th>\n",
       "      <td>18 Personas súper inteligentes que merecen tod...</td>\n",
       "      <td>BuzzFeed México</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37161</th>\n",
       "      <td>Salut nazi, «extermination» des Arabes: à Lyon...</td>\n",
       "      <td>BuzzFeed France News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>「上野学園大学」が経営陣を批判した教授を相次ぎ解雇　「無効だ」と裁判に……</td>\n",
       "      <td>BuzzFeed Japan News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19773</th>\n",
       "      <td>佐々木希が結婚報告でおのろけ、おやすみのチューは「ん〜たまにするね」</td>\n",
       "      <td>BuzzFeed Japan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>En pleno siglo XXI, el gobernador de Nuevo Leó...</td>\n",
       "      <td>BuzzFeed México</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>Mr. Modi And Mr. Jaitley, I'm Pretty Sure I Ne...</td>\n",
       "      <td>BuzzFeed India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>19 Bilder, von denen du Albträume bekommst, we...</td>\n",
       "      <td>BuzzFeed Deutschland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16429</th>\n",
       "      <td>Un collectif demande la vente de la pilule san...</td>\n",
       "      <td>BuzzFeed France News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>韓国人俳優に「ファッキン・コリア」　京都のヘイトスピーチを韓国メディアも報道</td>\n",
       "      <td>BuzzFeed Japan News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31501</th>\n",
       "      <td>You Truly Are 100% Emo If You Can Finish These...</td>\n",
       "      <td>BuzzFeed Quiz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29119</th>\n",
       "      <td>Contesta 5 preguntas y te diremos qué rol sexu...</td>\n",
       "      <td>BuzzFeed Español</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Este detalle en 'Unbreakable Kimmy Schmidt' pr...</td>\n",
       "      <td>BuzzFeed México</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19066</th>\n",
       "      <td>34 Memes, die du nur verstehst, wenn Katzen de...</td>\n",
       "      <td>BuzzFeed Deutschland</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36296</th>\n",
       "      <td>言葉をイラストに変換してくれるサイトがおもしろい！</td>\n",
       "      <td>BuzzFeed Japan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      buzz_campaign_name  \\\n",
       "1474   Caltech Professor Who Harassed Women Was Also ...   \n",
       "1631   The CEO Of A Huge Chicken Company Denied That ...   \n",
       "1670   A NASA Spacecraft Has Found Northern Lights An...   \n",
       "1782   Scientists Tell Navajo Farmers Their Water Is ...   \n",
       "2218   Why Americans Are So Damn Unhealthy, In 4 Shoc...   \n",
       "3606   This Is Why You Should Always Shower Before Sw...   \n",
       "4187   A Photographer Captured A Jaw-Dropping Weather...   \n",
       "7874   A Shocking 51-49 Senate Vote Just Kept Obama's...   \n",
       "7937   A Scientist Is Leaving Google For A Mental Hea...   \n",
       "8190   Obama Warns Inequality Could Derail Climate Ch...   \n",
       "8202   There's A Storm On Saturn And People Think It ...   \n",
       "10508  This Study Adds Even More Weight To Scientists...   \n",
       "10613  This Is Why Everyone Got Confused About The &q...   \n",
       "11477  Despite Donald Trump, Medical Science Just Got...   \n",
       "12057  Just A Bunch Of Truly Awesome Signs From The P...   \n",
       "13357  Don’t Believe The Big Story About Humans Roami...   \n",
       "13671  This Guy Gorged On Fish For A Year To See If O...   \n",
       "13794  Trump Is Ordering A Review Of All National Mon...   \n",
       "13875  The Science March Was Political. Its Organizer...   \n",
       "14549  These Native American Scholars Marched For Ind...   \n",
       "14628  15 Climate Change Facts That You'll Know Are T...   \n",
       "14674  These March For Science Signs Are So Wonderful...   \n",
       "15077    This Is What The World Looks Like Without Water   \n",
       "15654      The Opioid Epidemic Is Actually Two Epidemics   \n",
       "15883  This Planet Around A Small, Cool Star May Be O...   \n",
       "15946        26 Science Tweets That Will Leave You Shook   \n",
       "17920  These Takeout Robots Won't Wipe Out Delivery J...   \n",
       "18024  California Shows The Rest Of The Country How T...   \n",
       "19318  This Sky Pool Lets You Swim Suspended 500 Feet...   \n",
       "20881  17 Cheat Sheets That Will Actually Help You Sl...   \n",
       "...                                                  ...   \n",
       "10528        Le résumé pas chiant du débat Macron-Le Pen   \n",
       "28562  12 situações em que as pessoas dramáticas semp...   \n",
       "29330          27 Things We Learned On Set With Dua Lipa   \n",
       "25063  18 blagues que tous les fans d'Harry Potter ap...   \n",
       "32851  9 Interesting Theories About Who The \"Riverdal...   \n",
       "27804  Les différences entre les universités français...   \n",
       "17655  The Ultimate &quot;RuPaul's Drag Race&quot; Se...   \n",
       "32112  Here's Why The World's Biggest Brands Are Blac...   \n",
       "26576  21 Secretos que los blogueros de comida nunca ...   \n",
       "27641  We Know The Exact Date You'll Be Abducted By A...   \n",
       "19539  Este quiz de comida te dirá si te sobra o te f...   \n",
       "27902  Here Is The Winner Of The \"One Book, One New Y...   \n",
       "31617  Theresa May Has Asked MPs To Help End Violence...   \n",
       "15893  Leave It To Tyler, The Creator And Bill Nye To...   \n",
       "20548  11 Struggles That Kinda Suck When Trying To Ge...   \n",
       "28526  Si vous ne portez que des vêtements noirs, vou...   \n",
       "30676  18 Personas súper inteligentes que merecen tod...   \n",
       "37161  Salut nazi, «extermination» des Arabes: à Lyon...   \n",
       "5522               「上野学園大学」が経営陣を批判した教授を相次ぎ解雇　「無効だ」と裁判に……   \n",
       "19773                 佐々木希が結婚報告でおのろけ、おやすみのチューは「ん〜たまにするね」   \n",
       "1097   En pleno siglo XXI, el gobernador de Nuevo Leó...   \n",
       "2812   Mr. Modi And Mr. Jaitley, I'm Pretty Sure I Ne...   \n",
       "2810   19 Bilder, von denen du Albträume bekommst, we...   \n",
       "16429  Un collectif demande la vente de la pilule san...   \n",
       "10952             韓国人俳優に「ファッキン・コリア」　京都のヘイトスピーチを韓国メディアも報道   \n",
       "31501  You Truly Are 100% Emo If You Can Finish These...   \n",
       "29119  Contesta 5 preguntas y te diremos qué rol sexu...   \n",
       "2499   Este detalle en 'Unbreakable Kimmy Schmidt' pr...   \n",
       "19066  34 Memes, die du nur verstehst, wenn Katzen de...   \n",
       "36296                          言葉をイラストに変換してくれるサイトがおもしろい！   \n",
       "\n",
       "      buzz_account_display_name  class  \n",
       "1474           BuzzFeed Science      1  \n",
       "1631           BuzzFeed Science      1  \n",
       "1670           BuzzFeed Science      1  \n",
       "1782           BuzzFeed Science      1  \n",
       "2218           BuzzFeed Science      1  \n",
       "3606           BuzzFeed Science      1  \n",
       "4187           BuzzFeed Science      1  \n",
       "7874           BuzzFeed Science      1  \n",
       "7937           BuzzFeed Science      1  \n",
       "8190           BuzzFeed Science      1  \n",
       "8202           BuzzFeed Science      1  \n",
       "10508          BuzzFeed Science      1  \n",
       "10613          BuzzFeed Science      1  \n",
       "11477          BuzzFeed Science      1  \n",
       "12057          BuzzFeed Science      1  \n",
       "13357          BuzzFeed Science      1  \n",
       "13671          BuzzFeed Science      1  \n",
       "13794          BuzzFeed Science      1  \n",
       "13875          BuzzFeed Science      1  \n",
       "14549          BuzzFeed Science      1  \n",
       "14628          BuzzFeed Science      1  \n",
       "14674          BuzzFeed Science      1  \n",
       "15077          BuzzFeed Science      1  \n",
       "15654          BuzzFeed Science      1  \n",
       "15883          BuzzFeed Science      1  \n",
       "15946          BuzzFeed Science      1  \n",
       "17920          BuzzFeed Science      1  \n",
       "18024          BuzzFeed Science      1  \n",
       "19318          BuzzFeed Science      1  \n",
       "20881          BuzzFeed Science      1  \n",
       "...                         ...    ...  \n",
       "10528      BuzzFeed France News      0  \n",
       "28562           BuzzFeed Brasil      0  \n",
       "29330            BuzzFeed Celeb      0  \n",
       "25063           BuzzFeed France      0  \n",
       "32851        BuzzFeed Australia      0  \n",
       "27804           BuzzFeed France      0  \n",
       "17655             BuzzFeed LGBT      0  \n",
       "32112         BuzzFeed Politics      0  \n",
       "26576          BuzzFeed Español      0  \n",
       "27641             BuzzFeed Quiz      0  \n",
       "19539        Quizzes En Español      0  \n",
       "27902           BuzzFeed Reader      0  \n",
       "31617      BuzzFeed UK Politics      0  \n",
       "15893      Obsessed by BuzzFeed      0  \n",
       "20548        BuzzFeed Australia      0  \n",
       "28526           BuzzFeed France      0  \n",
       "30676           BuzzFeed México      0  \n",
       "37161      BuzzFeed France News      0  \n",
       "5522        BuzzFeed Japan News      0  \n",
       "19773            BuzzFeed Japan      0  \n",
       "1097            BuzzFeed México      0  \n",
       "2812             BuzzFeed India      0  \n",
       "2810       BuzzFeed Deutschland      0  \n",
       "16429      BuzzFeed France News      0  \n",
       "10952       BuzzFeed Japan News      0  \n",
       "31501             BuzzFeed Quiz      0  \n",
       "29119          BuzzFeed Español      0  \n",
       "2499            BuzzFeed México      0  \n",
       "19066      BuzzFeed Deutschland      0  \n",
       "36296            BuzzFeed Japan      0  \n",
       "\n",
       "[146 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dr = train[train['buzz_post_buzz_id'] == 4456887].sort_values('buzz_post_created_at')\n",
    "def get_previous(X):\n",
    "    prev = -1\n",
    "    buzzid = train[train['buzz_external_id'] == X]['buzz_post_buzz_id'].values[0]    \n",
    "    created_at = train[train['buzz_external_id'] == X]['buzz_post_created_at'].values[0]    \n",
    "    tf = train[(train['buzz_post_buzz_id'] == buzzid)&(train['buzz_post_created_at'] < created_at)]\n",
    "    try:\n",
    "        prev = tf[-1:]['buzz_external_id'].values[0]\n",
    "        return prev\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "dr['previous_external_id'] = dr['buzz_external_id'].apply(get_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_external_id</th>\n",
       "      <th>buzz_external_id</th>\n",
       "      <th>buzz_post_created_at</th>\n",
       "      <th>buzz_post_buzz_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37197</th>\n",
       "      <td>-1</td>\n",
       "      <td>560066014088988_1228152523946997</td>\n",
       "      <td>2017-02-06 12:48:13.398595</td>\n",
       "      <td>4456887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36967</th>\n",
       "      <td>560066014088988_1228152523946997</td>\n",
       "      <td>491452930867938_1550064698340084</td>\n",
       "      <td>2017-02-06 18:26:53.590087</td>\n",
       "      <td>4456887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   previous_external_id                  buzz_external_id  \\\n",
       "37197                                -1  560066014088988_1228152523946997   \n",
       "36967  560066014088988_1228152523946997  491452930867938_1550064698340084   \n",
       "\n",
       "             buzz_post_created_at  buzz_post_buzz_id  \n",
       "37197  2017-02-06 12:48:13.398595            4456887  \n",
       "36967  2017-02-06 18:26:53.590087            4456887  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr[['previous_external_id', 'buzz_external_id', 'buzz_post_created_at', \"buzz_post_buzz_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###parameter tuning using grid search\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([\n",
    "                     ('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "#                      ('clf', LinearSVC()),\n",
    "#                      ('clf', RandomForestClassifier()),\n",
    "#                      ('clf', LogisticRegression()),\n",
    "                    ])\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1,3)], \n",
    "              'vect__max_features': [10,100,1000, 10000],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'tfidf__norm': ('l1', 'l2', None),\n",
    "              'clf': [MultinomialNB(), LinearSVC(), RandomForestClassifier(), LogisticRegression(),],\n",
    "#               'clf__alpha': (1e-2, 1e-3),\n",
    "             }\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_all['buzz_campaign_name'], X_all['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'tfidf__norm': 'l1',\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__max_features': 1000,\n",
       " 'vect__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76712328767123283"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
