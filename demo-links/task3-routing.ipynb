{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.stats.api import ols\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "filepath = '/Users/eshwarchandrasekharan/Desktop/repo/predict-pop/models-links/'\n",
    "train_df = pd.read_csv(filepath + 'radshift-links-previous-to-next-page-info.csv')\n",
    "\n",
    "one_hour_features = [\n",
    "       'consumptions_by_type__link_clicks',\n",
    "       'consumptions_by_type__other_clicks',\n",
    "       'reactions_like_total',\n",
    "       'stories_by_action_type__comment',\n",
    "       'stories_by_action_type__like',\n",
    "       'stories_by_action_type__share', \n",
    "        'engaged_fan',\n",
    "       'fan_reach', \n",
    "    'impressions',\n",
    "       'impressions_fan',\n",
    "                ]\n",
    "\n",
    "two_day_features = [\n",
    "       'twoday_consumptions_by_type__link_clicks',\n",
    "       'twoday_stories_by_action_type__share',\n",
    "]\n",
    "\n",
    "all_pages = train_df['page'].unique()\n",
    "cross_promotion_features = all_pages\n",
    "\n",
    "# train_features = one_hour_features\n",
    "# print(\"ONLY 1 HOUR PERFORMANCE IN PREVIOUS PAGE\")\n",
    "# print('SHARES:')\n",
    "# res = ols(y = train_df['next_shares'], x = train_df[train_features])\n",
    "# print(res)\n",
    "# print('CLICKS:')\n",
    "# res = ols(y = train_df['next_clicks'], x = train_df[train_features])\n",
    "# print(res)\n",
    "# train_features = one_hour_features + page_infos# + cross_promotion_features\n",
    "# for feat in cross_promotion_features:\n",
    "#     train_features.append(feat)\n",
    "# train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREE REGRESSION!\n",
      "Performance stats with page names, and also cross-promotion order included!\n",
      "No. of data-points =  38769\n",
      "Log scaled!\n",
      "Shares performance: Accuracy =  0.6575787588  ; Error (/100) =  0.212635134964\n",
      "Clicks performance: Accuracy =  0.721635998508  ; Error (/100) =  0.0910451690249\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import linear_model\n",
    "# clf = linear_model.LinearRegression()\n",
    "# print(\"LINEAR REGRESSION!\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf = DecisionTreeRegressor(max_depth = 10)\n",
    "print(\"TREE REGRESSION!\")\n",
    "\n",
    "# train_df = pd.read_csv('radshift-links-previous-to-next-page-info.csv')\n",
    "# all_pages = list(train_df.page.unique())\n",
    "\n",
    "print(\"Performance stats with page names, and also cross-promotion order included!\")\n",
    "# print(\"WITH cross-promotion features\")\n",
    "\n",
    "page_infos = ['page', 'next_page']\n",
    "\n",
    "# train_features = one_hour_features\n",
    "# train_features = one_hour_features + page_infos + cross_promotion_features\n",
    "train_features = one_hour_features + page_infos\n",
    "# train_features = cross_promotion_features + one_hour_features\n",
    "\n",
    "log_scale = 1\n",
    "# log_scale = 0\n",
    "\n",
    "if log_scale == 1:\n",
    "    for feat in one_hour_features:\n",
    "        train_df[feat] = np.log(train_df[feat] + 1)\n",
    "\n",
    "# cross_promote = 0\n",
    "cross_promote = 1\n",
    "\n",
    "if cross_promote == 1:\n",
    "    for feat in cross_promotion_features:\n",
    "        train_features.append(feat)\n",
    "        \n",
    "# train_features = two_day_features + one_hour_features + cross_promotion_features\n",
    "\n",
    "# for feats in (one_hour_features):\n",
    "#     train_df[feats] = np.log(train_df[feats] + 1)\n",
    "\n",
    "# lm = linear_model.LinearRegression(fit_intercept=True, normalize=True)\n",
    "cv = 10\n",
    "\n",
    "train_df['clicks_bucket'] = np.log(train_df['next_clicks'] + 1)\n",
    "train_df['share_bucket'] = np.log(train_df['next_shares']+1)\n",
    "# train_df['clicks_bucket'] = np.log(train_df['next_clicks'] + 1).astype(int)\n",
    "# train_df['share_bucket'] = np.log(train_df['next_shares']+1).astype(int)\n",
    "\n",
    "print(\"No. of data-points = \", len(train_df))\n",
    "\n",
    "if log_scale == 0:\n",
    "    print(\"Raw values!\")\n",
    "    y_clicks = train_df['next_clicks']\n",
    "    y_share = train_df['next_shares']\n",
    "else:\n",
    "    print(\"Log scaled!\")\n",
    "    y_clicks = train_df['clicks_bucket']\n",
    "    y_share = train_df['share_bucket']\n",
    "\n",
    "###generate DFs for analysis - X and Y\n",
    "X = train_df[train_features]\n",
    "####convert page_infos into dummies\n",
    "X = pd.get_dummies(data = X, columns=['page', 'next_page'])\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "fold = 0\n",
    "cv_folds = 10\n",
    "kf = KFold(n_splits = cv_folds, shuffle = True)\n",
    "\n",
    "clicks_accuracy = []\n",
    "clicks_error = []\n",
    "shares_accuracy = []\n",
    "shares_error = []\n",
    "\n",
    "share_cv_y_test = []\n",
    "share_cv_y_pred = []\n",
    "clicks_cv_y_test = []\n",
    "clicks_cv_y_pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"Fold = \", fold)\n",
    "#     print(\"Shares: Fold = \", fold)\n",
    "    y = y_share\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    ####\n",
    "    for pt in y_test:\n",
    "        share_cv_y_test.append(pt)\n",
    "    for pt in y_pred:\n",
    "        share_cv_y_pred.append(pt)\n",
    "        \n",
    "    accuracy = metrics.r2_score(y_test, y_pred)\n",
    "#     print(\"Cross-Predicted Accuracy (R2):\", accuracy)\n",
    "    shares_accuracy.append(accuracy)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    # print(\"Mean Absolute Error: \", mean_absolute_error(y, predictions))\n",
    "    error_percent = mean_absolute_error(y_test, y_pred)/y.mean()\n",
    "#     print(\"Mean values (share): \", y_test.mean(), \" | percent error: \",  error_percent)\n",
    "    shares_error.append(error_percent)\n",
    "    \n",
    "#     print(\"Clicks: Fold = \", fold)\n",
    "    y = y_clicks\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    ####\n",
    "    for pt in y_test:\n",
    "        clicks_cv_y_test.append(pt)\n",
    "    for pt in y_pred:\n",
    "        clicks_cv_y_pred.append(pt)\n",
    "\n",
    "    accuracy = metrics.r2_score(y_test, y_pred)\n",
    "#     print(\"Cross-Predicted Accuracy (R2):\", accuracy)\n",
    "    clicks_accuracy.append(accuracy)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    # print(\"Mean Absolute Error: \", mean_absolute_error(y, predictions))\n",
    "    error_percent = mean_absolute_error(y_test, y_pred)/y.mean()\n",
    "#     print(\"Mean values (share): \", y_test.mean(), \" | percent error: \",  error_percent)\n",
    "    clicks_error.append(error_percent)\n",
    "    fold += 1\n",
    "print(\"Shares performance: Accuracy = \", np.mean(shares_accuracy), \" ; Error (/100) = \", np.mean(shares_error))\n",
    "print(\"Clicks performance: Accuracy = \", np.mean(clicks_accuracy), \" ; Error (/100) = \", np.mean(clicks_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 3: Routing!\n",
    "# 1) \n",
    "# TREE REGRESSION!\n",
    "# Performance stats with page names, and also cross-promotion order included!\n",
    "# No. of data-points =  38769\n",
    "# Raw values!\n",
    "# Shares performance: Accuracy =  0.793776564986  ; Error (/100) =  0.564984135071\n",
    "# Clicks performance: Accuracy =  0.803486044908  ; Error (/100) =  0.420198927612\n",
    "    \n",
    "# ----\n",
    "# 2)\n",
    "# TREE REGRESSION!\n",
    "# Performance stats with page names, and also cross-promotion order included!\n",
    "# No. of data-points =  38769\n",
    "# Log scaled!\n",
    "# Shares performance: Accuracy =  0.6575787588  ; Error (/100) =  0.212635134964\n",
    "# Clicks performance: Accuracy =  0.721635998508  ; Error (/100) =  0.0910451690249\n",
    "    \n",
    "# 2.1) Convert log-scale predictions/test to exponents and compute R2/errors\n",
    "\n",
    "# Shares!\n",
    "# R2:  0.779841664501\n",
    "# Error (\\100):  0.516329728148\n",
    "# Mean:  118.348990173\n",
    "# Clicks!\n",
    "# R2:  0.779658862269\n",
    "# Error (\\100):  0.398451498565\n",
    "# Mean:  10139.2730016\n",
    "# ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
