{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshwarchandrasekharan/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "###fit the regression \n",
    "import pandas as pd\n",
    "from pandas.stats.api import ols\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "filepath = \"/Users/eshwarchandrasekharan/Desktop/repo/predict-pop/models-links/\"\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR REGRESSION!\n",
      "LOG SCALED!\n",
      "No. of data-points =  85591\n",
      "Fold =  0\n",
      "Fold =  1\n",
      "Fold =  2\n",
      "Fold =  3\n",
      "Fold =  4\n",
      "Fold =  5\n",
      "Fold =  6\n",
      "Fold =  7\n",
      "Fold =  8\n",
      "Fold =  9\n",
      "Share performance: Accuracy =  0.884659153102  ; Error (/100) =  0.11573029429\n",
      "Clicks performance: Accuracy =  0.918368255661  ; Error (/100) =  0.0439799564654\n"
     ]
    }
   ],
   "source": [
    "##given performance in the previous page, where should I post next?\n",
    "import pandas as pd\n",
    "from pandas.stats.api import ols\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "print(\"LINEAR REGRESSION!\")\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# clf = DecisionTreeRegressor(max_depth=10)\n",
    "# print(\"TREE REGRESSION!\")\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# clf =  AdaBoostClassifier()\n",
    "# print(\"ADABOOST!\")\n",
    "\n",
    "# log_scaling = 0\n",
    "log_scaling = 1\n",
    "\n",
    "if log_scaling == 1:\n",
    "    print(\"LOG SCALED!\")\n",
    "else:\n",
    "    print(\"RAW COUNTS!\")\n",
    "# train_df = pd.read_csv(filepath + 'jan-jun-2017-videos-post-type-2-16.csv')\n",
    "train_df = pd.read_csv(filepath + 'radshift_links_cross_posting_info.csv')\n",
    "train_df = train_df.fillna(0)\n",
    "\n",
    "# video_df.shape, video_df['external_id'].unique().shape\n",
    "train_df = train_df.sort_values('stats_date', ascending = False).drop_duplicates(subset=['external_id'], keep = 'last')\n",
    "\n",
    "one_hour_features = [\n",
    "                       'consumptions_by_type__link_clicks',\n",
    "       'consumptions_by_type__other_clicks',\n",
    "       'reactions_like_total',\n",
    "       'stories_by_action_type__comment',\n",
    "       'stories_by_action_type__like',\n",
    "       'stories_by_action_type__share', \n",
    "        'engaged_fan',\n",
    "       'fan_reach', \n",
    "    'impressions',\n",
    "       'impressions_fan',\n",
    "               ]\n",
    "\n",
    "#        'twoday_consumptions_by_type__link_clicks',\n",
    "#        'twoday_stories_by_action_type__share',\n",
    "\n",
    "\n",
    "train_features = one_hour_features\n",
    "\n",
    "if log_scaling == 1:\n",
    "    for feats in (one_hour_features):\n",
    "        train_df[feats] = np.log(train_df[feats] + 1)\n",
    "\n",
    "# lm = linear_model.LinearRegression(fit_intercept=True, normalize=True)\n",
    "cv = 10\n",
    "\n",
    "# train_df['10s_bucket'] = np.log(train_df['twodays_video_views_10s_organic'] + 1).astype(int)\n",
    "# train_df['30s_bucket'] = np.log(train_df['twodays_video_complete_views_30s_organic'] + 1).astype(int)\n",
    "# train_df['complete_views_bucket'] = np.log(train_df['twodays_video_complete_views_organic'] + 1).astype(int)\n",
    "\n",
    "print(\"No. of data-points = \", len(train_df))\n",
    "\n",
    "if log_scaling == 1:\n",
    "    y_share = np.log(1+train_df['twoday_stories_by_action_type__share']).astype(int)\n",
    "    y_clicks = np.log(1+train_df['twoday_consumptions_by_type__link_clicks']).astype(int)\n",
    "else:\n",
    "    y_share = train_df['twoday_stories_by_action_type__share']\n",
    "    y_clicks = train_df['twoday_consumptions_by_type__link_clicks']\n",
    "\n",
    "# y_10s = train_df['twodays_video_views_10s_organic']\n",
    "# y_30s = train_df['twodays_video_complete_views_30s_organic']\n",
    "# y_complete = train_df['twodays_video_complete_views_organic']\n",
    "###\n",
    "# y_10s = train_df['10s_bucket']\n",
    "# y_30s = train_df['30s_bucket']\n",
    "# y_complete = train_df['complete_views_bucket']\n",
    "\n",
    "###generate DFs for analysis - X and Y\n",
    "X = train_df[train_features]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "fold = 0\n",
    "cv_folds = 10\n",
    "kf = KFold(n_splits = cv_folds, shuffle = True)\n",
    "\n",
    "accuracy_10s = []\n",
    "error_10s = []\n",
    "accuracy_30s = []\n",
    "error_30s = []\n",
    "accuracy_complete = []\n",
    "error_complete = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"Fold = \", fold)\n",
    "#     print(\"Shares: Fold = \", fold)\n",
    "    y = y_share\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "        \n",
    "    accuracy = metrics.r2_score(y_test, y_pred)\n",
    "#     print(\"Cross-Predicted Accuracy (R2):\", accuracy)\n",
    "    accuracy_10s.append(accuracy)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    # print(\"Mean Absolute Error: \", mean_absolute_error(y, predictions))\n",
    "    error_percent = mean_absolute_error(y_test, y_pred)/y.mean()\n",
    "#     print(\"Mean values (share): \", y_test.mean(), \" | percent error: \",  error_percent)\n",
    "    error_10s.append(error_percent)\n",
    "    \n",
    "#     print(\"Clicks: Fold = \", fold)\n",
    "    y = y_clicks\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.r2_score(y_test, y_pred)\n",
    "#     print(\"Cross-Predicted Accuracy (R2):\", accuracy)\n",
    "    accuracy_30s.append(accuracy)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    # print(\"Mean Absolute Error: \", mean_absolute_error(y, predictions))\n",
    "    error_percent = mean_absolute_error(y_test, y_pred)/y.mean()\n",
    "#     print(\"Mean values (share): \", y_test.mean(), \" | percent error: \",  error_percent)\n",
    "    error_30s.append(error_percent)\n",
    "    \n",
    "    fold += 1\n",
    "    \n",
    "print(\"Share performance: Accuracy = \", np.mean(accuracy_10s), \" ; Error (/100) = \", np.mean(error_10s))\n",
    "print(\"Clicks performance: Accuracy = \", np.mean(accuracy_30s), \" ; Error (/100) = \", np.mean(error_30s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR REGRESSION!\n",
      "RAW COUNTS!\n",
      "No. of data-points =  85591\n",
      "Share performance: Accuracy =  0.815402613263  ; Error (/100) =  0.40553753643\n",
      "Clicks performance: Accuracy =  0.909194310088  ; Error (/100) =  0.254577290434\n"
     ]
    }
   ],
   "source": [
    "##given performance in the previous page, where should I post next?\n",
    "import pandas as pd\n",
    "from pandas.stats.api import ols\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "print(\"LINEAR REGRESSION!\")\n",
    "\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# clf = DecisionTreeRegressor(max_depth=10)\n",
    "# print(\"TREE REGRESSION!\")\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# clf =  AdaBoostClassifier()\n",
    "# print(\"ADABOOST!\")\n",
    "\n",
    "log_scaling = 0\n",
    "# log_scaling = 1\n",
    "\n",
    "if log_scaling == 1:\n",
    "    print(\"LOG SCALED!\")\n",
    "else:\n",
    "    print(\"RAW COUNTS!\")\n",
    "# train_df = pd.read_csv(filepath + 'jan-jun-2017-videos-post-type-2-16.csv')\n",
    "train_df = pd.read_csv(filepath + 'radshift_links_cross_posting_info.csv')\n",
    "train_df = train_df.fillna(0)\n",
    "\n",
    "# video_df.shape, video_df['external_id'].unique().shape\n",
    "train_df = train_df.sort_values('stats_date', ascending = False).drop_duplicates(subset=['external_id'], keep = 'last')\n",
    "\n",
    "one_hour_features = [\n",
    "                       'consumptions_by_type__link_clicks',\n",
    "       'consumptions_by_type__other_clicks',\n",
    "       'reactions_like_total',\n",
    "       'stories_by_action_type__comment',\n",
    "       'stories_by_action_type__like',\n",
    "       'stories_by_action_type__share', \n",
    "        'engaged_fan',\n",
    "       'fan_reach', \n",
    "    'impressions',\n",
    "       'impressions_fan',\n",
    "               ]\n",
    "\n",
    "#        'twoday_consumptions_by_type__link_clicks',\n",
    "#        'twoday_stories_by_action_type__share',\n",
    "\n",
    "\n",
    "train_features = one_hour_features\n",
    "\n",
    "all_pages = train_df['page'].unique()\n",
    "\n",
    "for pg in all_pages:\n",
    "    train_features.append(pg)\n",
    "\n",
    "alt_inf = len(all_pages) + 1\n",
    "train_df = train_df.replace(math.inf, alt_inf)\n",
    "\n",
    "if log_scaling == 1:\n",
    "    for feats in (one_hour_features):\n",
    "        train_df[feats] = np.log(train_df[feats] + 1)\n",
    "\n",
    "# lm = linear_model.LinearRegression(fit_intercept=True, normalize=True)\n",
    "cv = 10\n",
    "\n",
    "# train_df['10s_bucket'] = np.log(train_df['twodays_video_views_10s_organic'] + 1).astype(int)\n",
    "# train_df['30s_bucket'] = np.log(train_df['twodays_video_complete_views_30s_organic'] + 1).astype(int)\n",
    "# train_df['complete_views_bucket'] = np.log(train_df['twodays_video_complete_views_organic'] + 1).astype(int)\n",
    "\n",
    "print(\"No. of data-points = \", len(train_df))\n",
    "\n",
    "if log_scaling == 1:\n",
    "    y_share = np.log(1+train_df['twoday_stories_by_action_type__share']).astype(int)\n",
    "    y_clicks = np.log(1+train_df['twoday_consumptions_by_type__link_clicks']).astype(int)\n",
    "else:\n",
    "    y_share = train_df['twoday_stories_by_action_type__share']\n",
    "    y_clicks = train_df['twoday_consumptions_by_type__link_clicks']\n",
    "\n",
    "# y_10s = train_df['twodays_video_views_10s_organic']\n",
    "# y_30s = train_df['twodays_video_complete_views_30s_organic']\n",
    "# y_complete = train_df['twodays_video_complete_views_organic']\n",
    "###\n",
    "# y_10s = train_df['10s_bucket']\n",
    "# y_30s = train_df['30s_bucket']\n",
    "# y_complete = train_df['complete_views_bucket']\n",
    "\n",
    "###generate DFs for analysis - X and Y\n",
    "X = train_df[train_features]\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "fold = 0\n",
    "cv_folds = 10\n",
    "kf = KFold(n_splits = cv_folds, shuffle = True)\n",
    "\n",
    "accuracy_10s = []\n",
    "error_10s = []\n",
    "accuracy_30s = []\n",
    "error_30s = []\n",
    "accuracy_complete = []\n",
    "error_complete = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"Fold = \", fold)\n",
    "#     print(\"Shares: Fold = \", fold)\n",
    "    y = y_share\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "        \n",
    "    accuracy = metrics.r2_score(y_test, y_pred)\n",
    "#     print(\"Cross-Predicted Accuracy (R2):\", accuracy)\n",
    "    accuracy_10s.append(accuracy)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    # print(\"Mean Absolute Error: \", mean_absolute_error(y, predictions))\n",
    "    error_percent = mean_absolute_error(y_test, y_pred)/y.mean()\n",
    "#     print(\"Mean values (share): \", y_test.mean(), \" | percent error: \",  error_percent)\n",
    "    error_10s.append(error_percent)\n",
    "    \n",
    "#     print(\"Clicks: Fold = \", fold)\n",
    "    y = y_clicks\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.r2_score(y_test, y_pred)\n",
    "#     print(\"Cross-Predicted Accuracy (R2):\", accuracy)\n",
    "    accuracy_30s.append(accuracy)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    # print(\"Mean Absolute Error: \", mean_absolute_error(y, predictions))\n",
    "    error_percent = mean_absolute_error(y_test, y_pred)/y.mean()\n",
    "#     print(\"Mean values (share): \", y_test.mean(), \" | percent error: \",  error_percent)\n",
    "    error_30s.append(error_percent)\n",
    "    \n",
    "    fold += 1\n",
    "    \n",
    "print(\"Share performance: Accuracy = \", np.mean(accuracy_10s), \" ; Error (/100) = \", np.mean(error_10s))\n",
    "print(\"Clicks performance: Accuracy = \", np.mean(accuracy_30s), \" ; Error (/100) = \", np.mean(error_30s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
